{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.13175 , -0.25517 , -0.067915,  0.26193 , -0.26155 ,  0.23569 ,\n",
       "        0.13077 , -0.011801,  1.7659  ,  0.20781 ,  0.26198 , -0.16428 ,\n",
       "       -0.84642 ,  0.020094,  0.070176,  0.39778 ,  0.15278 , -0.20213 ,\n",
       "       -1.6184  , -0.54327 , -0.17856 ,  0.53894 ,  0.49868 , -0.10171 ,\n",
       "        0.66265 , -1.7051  ,  0.057193, -0.32405 , -0.66835 ,  0.26654 ,\n",
       "        2.842   ,  0.26844 , -0.59537 , -0.5004  ,  1.5199  ,  0.039641,\n",
       "        1.6659  ,  0.99758 , -0.5597  , -0.70493 , -0.0309  , -0.28302 ,\n",
       "       -0.13564 ,  0.6429  ,  0.41491 ,  1.2362  ,  0.76587 ,  0.97798 ,\n",
       "        0.58507 , -0.30176 ], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict={}\n",
    "with open('C:/Users/marci/Documents/Portfolio/TwitterClassification/TwitterStream/data/glove.6B.50d.txt','rb') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], \"float32\")\n",
    "        embeddings_dict[word] = vector\n",
    "embeddings_dict[b'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_closest_embeddings(embedding):\n",
    "   return sorted(embeddings_dict.keys(), key=lambda word:\n",
    "       spatial.distance.euclidean(embeddings_dict[word], embedding)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = {\n",
    "    'videogame': 0,\n",
    "    'music': 1,\n",
    "    'city': 2,\n",
    "    'sport': 3\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogame_words = find_closest_embeddings(embeddings_dict[b\"videogame\"])\n",
    "music_words = find_closest_embeddings(embeddings_dict[b\"music\"])\n",
    "city_words = find_closest_embeddings(embeddings_dict[b\"city\"])\n",
    "sport_words = find_closest_embeddings(embeddings_dict[b\"sport\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogame_similars = np.asarray(videogame_words[:500])\n",
    "music_similars = np.asarray(music_words[:500])\n",
    "city_similars = np.asarray(city_words[:500])\n",
    "sport_similars = np.asarray(sport_words[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([205,  28,  23, ..., 254, 416,  90])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(0, 500)\n",
    "xU, xL = x + 500, x\n",
    "prob = ss.norm.cdf(xU, scale = 249) - ss.norm.cdf(xL, scale = 250)\n",
    "prob = prob / prob.sum() # normalize the probabilities so their sum is 1\n",
    "rand_arr = np.random.choice(x, size = 16*10000, p = prob)\n",
    "plt.hist(rand_arr, bins=len(x))\n",
    "rand_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artificial_phrase_matrix(seed):\n",
    "    np.random.seed(seed)\n",
    "    artificial_phrase_matrix = []\n",
    "    for i in range(10000):\n",
    "        phrase_size = np.random.randint(1,17)\n",
    "        artificial_phrase_matrix.append(np.random.choice(x, size = phrase_size, p = prob))\n",
    "    return artificial_phrase_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "videogame_apm = get_artificial_phrase_matrix(1)\n",
    "music_apm = get_artificial_phrase_matrix(2)\n",
    "city_apm = get_artificial_phrase_matrix(3)\n",
    "sport_apm = get_artificial_phrase_matrix(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_db = {\n",
    "    'videogame':{\n",
    "        'apm': videogame_apm, \n",
    "        'similar_words': videogame_similars\n",
    "        },\n",
    "    'music': {\n",
    "        'apm': music_apm,\n",
    "        'similar_words': music_similars\n",
    "        },\n",
    "    'city': {\n",
    "        'apm': city_apm,\n",
    "        'similar_words': city_similars\n",
    "        },\n",
    "    'sport': {\n",
    "        'apm': sport_apm,\n",
    "        'similar_words': sport_similars\n",
    "        }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  videogame\n",
      "[array([b'licensees', b'alchemist', b'toonz', b'ics', b'snes', b'vpro'],\n",
      "      dtype='|S17'), array([b'then-new', b'vpro', b'pgp', b'ruggedized', b'vb', b'visio',\n",
      "       b'hobbyist', b'ps3'], dtype='|S17')]\n",
      "subject:  music\n",
      "[array([b'musician', b'soulful', b'new', b'dancing', b'trio', b'genre',\n",
      "       b\"'80s\", b'performed', b'dancing'], dtype='|S16'), array([b'composed', b'hip', b'featured', b'blues', b'musician'],\n",
      "      dtype='|S16')]\n",
      "subject:  city\n",
      "[array([b'suburbs', b'already', b'northwest', b'georgia', b'community',\n",
      "       b'cities', b'central', b'northeastern', b'part', b'heavily',\n",
      "       b'outskirts'], dtype='|S13'), array([b'including', b'center', b'newark', b'seen', b'downtown',\n",
      "       b'waterfront', b'queens', b'public', b'offices', b'harlem',\n",
      "       b'alone', b'northeast', b'chicago', b'school', b'today'],\n",
      "      dtype='|S13')]\n",
      "subject:  sport\n",
      "[array([b'once', b'youth', b'paralympic', b'sportscar', b'good', b'model',\n",
      "       b'motorcycle', b'here', b'doing', b'means', b'sports'],\n",
      "      dtype='|S13'), array([b'importantly', b'rarely', b'bicycle', b'good', b'sports',\n",
      "       b'athletics', b'competes', b'jockey', b'amateur', b'nordic',\n",
      "       b'baseball', b'example', b'youth', b'formula', b'neither'],\n",
      "      dtype='|S13')]\n"
     ]
    }
   ],
   "source": [
    "for subject_name in artificial_db.keys():\n",
    "    subject = artificial_db[subject_name]\n",
    "    sents = []\n",
    "    for idx_list in subject['apm']:\n",
    "        sent = subject['similar_words'][idx_list]\n",
    "        sents.append(sent)\n",
    "    subject['sentences'] = sents\n",
    "    print('subject: ', subject_name)\n",
    "    print(subject['sentences'][:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subject:  videogame\n",
      "['licensees alchemist toonz ics snes vpro', 'then-new vpro pgp ruggedized vb visio hobbyist ps3']\n",
      "subject:  music\n",
      "[\"musician soulful new dancing trio genre '80s performed dancing\", 'composed hip featured blues musician']\n",
      "subject:  city\n",
      "['suburbs already northwest georgia community cities central northeastern part heavily outskirts', 'including center newark seen downtown waterfront queens public offices harlem alone northeast chicago school today']\n",
      "subject:  sport\n",
      "['once youth paralympic sportscar good model motorcycle here doing means sports', 'importantly rarely bicycle good sports athletics competes jockey amateur nordic baseball example youth formula neither']\n"
     ]
    }
   ],
   "source": [
    "for subject_name in artificial_db.keys():\n",
    "    subject = artificial_db[subject_name]\n",
    "    phrases = []\n",
    "    for byte_list in subject['sentences']:\n",
    "        word_list = list(map(lambda b: b.decode('UTF-8'), byte_list))\n",
    "        phrase = ' '.join(word_list)\n",
    "        phrases.append(phrase)\n",
    "    subject['phrases'] = phrases\n",
    "    print('subject: ', subject_name)\n",
    "    print(subject['phrases'][:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1537864080857649152</td>\n",
       "      <td>Happy birthday!!!!!</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537860083668832256</td>\n",
       "      <td>Jeongin now joining the crew and his weapon is...</td>\n",
       "      <td>['Person', 'Musician', 'Music Genre']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1537825048635097088</td>\n",
       "      <td>Interviewed more than 400 people and confirmed...</td>\n",
       "      <td>['Brand Vertical', 'Brand Category', 'Brand']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1537837652522651649</td>\n",
       "      <td>Ass torture !!  this is called ass torture, wh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1537845005129326592</td>\n",
       "      <td>Need for help!! im a victim of domestic abuse ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1537864080857649152                                Happy birthday!!!!!   \n",
       "1  1537860083668832256  Jeongin now joining the crew and his weapon is...   \n",
       "2  1537825048635097088  Interviewed more than 400 people and confirmed...   \n",
       "3  1537837652522651649  Ass torture !!  this is called ass torture, wh...   \n",
       "4  1537845005129326592  Need for help!! im a victim of domestic abuse ...   \n",
       "\n",
       "                                     annotations  \n",
       "0                                             []  \n",
       "1          ['Person', 'Musician', 'Music Genre']  \n",
       "2  ['Brand Vertical', 'Brand Category', 'Brand']  \n",
       "3                                             []  \n",
       "4                                             []  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tweets = pd.read_csv('C:/Users/marci/Documents/Portfolio/TwitterClassification/TwitterStream/data/random_tweets_cleaned.csv')\n",
    "random_tweets = random_tweets.dropna()\n",
    "random_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer()\n",
    "random_tweets_phrases = list(random_tweets.text)\n",
    "for subject in artificial_db:\n",
    "    random_tweets_phrases += artificial_db[subject]['phrases']\n",
    "cv = cv.fit(random_tweets_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subject_name in artificial_db:\n",
    "    subject = artificial_db[subject_name]\n",
    "    subject['sparse_vectorized_phrases'] = cv.transform(subject['phrases'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78480"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quantidade de palavras encontradas\n",
    "len(cv.vocabulary_.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing train and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<40000x78480 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 343978 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrixes = []\n",
    "for subject_name in targets:\n",
    "    matrixes.append(artificial_db[subject_name]['sparse_vectorized_phrases'])\n",
    "X = sparse.vstack(matrixes)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 3 3 3] (40000,)\n"
     ]
    }
   ],
   "source": [
    "target_values = []\n",
    "for subject_name, target in targets.items():\n",
    "    length = artificial_db[subject_name]['sparse_vectorized_phrases'].shape[0]\n",
    "    values = np.zeros(length, dtype=int) + target\n",
    "    target_values.append(values)\n",
    "y = np.concatenate(target_values, axis=0)\n",
    "print(y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 78480)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import cross_validate, ShuffleSplit\n",
    "from sklearn import metrics\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model with sparse data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "_penalty = 'l1'\n",
    "_solver = 'liblinear'\n",
    "clf_lr_1 = LogisticRegression(penalty=_penalty, solver=_solver)\n",
    "\n",
    "_penalty = 'l2'\n",
    "_solver = 'liblinear'\n",
    "clf_lr_2 = LogisticRegression(penalty=_penalty, solver=_solver)\n",
    "\n",
    "_loss = 'hinge'\n",
    "_penalty = 'l1'\n",
    "clf_sgd_1 = SGDClassifier(loss=_loss, penalty=_penalty)\n",
    "\n",
    "_loss = 'perceptron'\n",
    "_penalty = 'l1'\n",
    "clf_sgd_2 = SGDClassifier(loss=_loss, penalty=_penalty)\n",
    "\n",
    "_loss = 'hinge'\n",
    "_penalty = 'l2'\n",
    "clf_sgd_3 = SGDClassifier(loss=_loss, penalty=_penalty)\n",
    "\n",
    "_loss = 'perceptron'\n",
    "_penalty = 'l2'\n",
    "clf_sgd_4 = SGDClassifier(loss=_loss, penalty=_penalty)\n",
    "\n",
    "clfs = [clf_lr_1, clf_lr_2, clf_sgd_1, clf_sgd_2, clf_sgd_3, clf_sgd_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf):\n",
    "    \n",
    "    #training\n",
    "    print(\"=\"*80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    \n",
    "    _scoring = {'Accuracy':'accuracy', 'log loss':'neg_log_loss'}\n",
    "    _scoring = {'Accuracy':'accuracy', 'f1 score':'f1_weighted'}\n",
    "    _cv = ShuffleSplit(n_splits=10, test_size=.25)\n",
    "    cv_results = cross_validate(clf, X, y, scoring=_scoring, cv=_cv)\n",
    "\n",
    "    #print(\"train time: %0.3fs\" % cv_results['fit_time'])\n",
    "    #print(\"score time:  %0.3fs\" % cv_results['score_time'])\n",
    "    scores = cv_results\n",
    "    print('\\nMeans:')\n",
    "    for metric in _scoring:\n",
    "        print(\"%s:   %0.3f\" % (metric, cv_results['test_'+metric].mean()))\n",
    "    \n",
    "    #print('\\nRaw results:')\n",
    "    #for metric in _scoring:\n",
    "    #    print(\"%s:   \" % metric, cv_results['test_'+metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training: \n",
      "LogisticRegression(penalty='l1', solver='liblinear')\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.989\n",
      "f1 score:   0.989\n",
      "================================================================================\n",
      "Training: \n",
      "LogisticRegression(solver='liblinear')\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.996\n",
      "f1 score:   0.996\n",
      "================================================================================\n",
      "Training: \n",
      "SGDClassifier(penalty='l1')\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.982\n",
      "f1 score:   0.982\n",
      "================================================================================\n",
      "Training: \n",
      "SGDClassifier(loss='perceptron', penalty='l1')\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.965\n",
      "f1 score:   0.965\n",
      "================================================================================\n",
      "Training: \n",
      "SGDClassifier()\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.995\n",
      "f1 score:   0.995\n",
      "================================================================================\n",
      "Training: \n",
      "SGDClassifier(loss='perceptron')\n",
      "\n",
      "Means:\n",
      "Accuracy:   0.991\n",
      "f1 score:   0.991\n"
     ]
    }
   ],
   "source": [
    "for clf in clfs:\n",
    "    evaluate_model(clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5x78480 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 63 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.transform(random_tweets.text.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1537864080857649152</td>\n",
       "      <td>Happy birthday!!!!!</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537860083668832256</td>\n",
       "      <td>Jeongin now joining the crew and his weapon is...</td>\n",
       "      <td>[person, musician, music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1537825048635097088</td>\n",
       "      <td>Interviewed more than 400 people and confirmed...</td>\n",
       "      <td>[brand vertical, brand category, brand]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1537837652522651649</td>\n",
       "      <td>Ass torture !!  this is called ass torture, wh...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1537845005129326592</td>\n",
       "      <td>Need for help!! im a victim of domestic abuse ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130168</th>\n",
       "      <td>1537834573916086273</td>\n",
       "      <td>Kue lapis nct dream</td>\n",
       "      <td>[person, person, musician, musician, music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130169</th>\n",
       "      <td>1537854815635927040</td>\n",
       "      <td>My comfort in the chaos..    ||</td>\n",
       "      <td>[person, actor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130170</th>\n",
       "      <td>1537828257290407936</td>\n",
       "      <td>Guys, ini nct dream era apa? gils, their side ...</td>\n",
       "      <td>[person, person, musician, musician, music]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130171</th>\n",
       "      <td>1537832359306792966</td>\n",
       "      <td>Ingat ttp slalu :  ,  ,</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130172</th>\n",
       "      <td>1537843973330374656</td>\n",
       "      <td>So excited to see beomgyu</td>\n",
       "      <td>[person, musician, music]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130173 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "0       1537864080857649152   \n",
       "1       1537860083668832256   \n",
       "2       1537825048635097088   \n",
       "3       1537837652522651649   \n",
       "4       1537845005129326592   \n",
       "...                     ...   \n",
       "130168  1537834573916086273   \n",
       "130169  1537854815635927040   \n",
       "130170  1537828257290407936   \n",
       "130171  1537832359306792966   \n",
       "130172  1537843973330374656   \n",
       "\n",
       "                                                     text  \\\n",
       "0                                     Happy birthday!!!!!   \n",
       "1       Jeongin now joining the crew and his weapon is...   \n",
       "2       Interviewed more than 400 people and confirmed...   \n",
       "3       Ass torture !!  this is called ass torture, wh...   \n",
       "4       Need for help!! im a victim of domestic abuse ...   \n",
       "...                                                   ...   \n",
       "130168                                Kue lapis nct dream   \n",
       "130169                    My comfort in the chaos..    ||   \n",
       "130170  Guys, ini nct dream era apa? gils, their side ...   \n",
       "130171                            Ingat ttp slalu :  ,  ,   \n",
       "130172                          So excited to see beomgyu   \n",
       "\n",
       "                                        annotations  \n",
       "0                                                []  \n",
       "1                         [person, musician, music]  \n",
       "2           [brand vertical, brand category, brand]  \n",
       "3                                                []  \n",
       "4                                                []  \n",
       "...                                             ...  \n",
       "130168  [person, person, musician, musician, music]  \n",
       "130169                              [person, actor]  \n",
       "130170  [person, person, musician, musician, music]  \n",
       "130171                                           []  \n",
       "130172                    [person, musician, music]  \n",
       "\n",
       "[130173 rows x 3 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tweets['annotations'] = random_tweets['annotations'].str.lower()\n",
    "random_tweets['annotations'] = random_tweets['annotations'].str.replace('music genre', 'music')\n",
    "random_tweets['annotations'] = random_tweets['annotations'].str.replace('video game', 'videogame')\n",
    "random_tweets['annotations'] = random_tweets['annotations'].str.replace('cities', 'city')\n",
    "random_tweets['annotations'] = random_tweets['annotations'].apply(ast.literal_eval)\n",
    "random_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['actor', 'american football game', 'animals', 'athlete',\n",
       "       'award show', 'baseball game', 'basketball game', 'book',\n",
       "       'book genre'], dtype='<U32')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotation_names = np.unique(np.concatenate(random_tweets['annotations']))\n",
    "annotation_names[:9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'person': 28233,\n",
       "         'musician': 9619,\n",
       "         'music': 7988,\n",
       "         'brand vertical': 6076,\n",
       "         'brand category': 10960,\n",
       "         'brand': 12597,\n",
       "         'actor': 3074,\n",
       "         'movie': 900,\n",
       "         'videogame': 1878,\n",
       "         'reoccurring trends': 378,\n",
       "         'technology': 1265,\n",
       "         'interests and hobbies': 5371,\n",
       "         'athlete': 3401,\n",
       "         'politician': 7484,\n",
       "         'ongoing news story': 2510,\n",
       "         'events [entity service]': 6071,\n",
       "         'movie genre': 909,\n",
       "         'political body': 1338,\n",
       "         'city': 1225,\n",
       "         'interests and hobbies category': 7907,\n",
       "         'interests and hobbies vertical': 5491,\n",
       "         'entities [entity service]': 6965,\n",
       "         'digital assets & crypto': 1159,\n",
       "         'food': 429,\n",
       "         'google product taxonomy': 747,\n",
       "         'tv shows': 8271,\n",
       "         'sports event': 1537,\n",
       "         'sport': 4261,\n",
       "         'sports team': 3067,\n",
       "         'sports league': 3491,\n",
       "         'basketball game': 367,\n",
       "         'journalist': 794,\n",
       "         'global tv show': 1491,\n",
       "         'music album': 928,\n",
       "         'tv episodes': 515,\n",
       "         'holiday': 947,\n",
       "         'local news': 381,\n",
       "         'states': 1301,\n",
       "         'fan community': 637,\n",
       "         'digital creator': 428,\n",
       "         'exercise & fitness': 242,\n",
       "         'multimedia franchise': 1885,\n",
       "         'entertainment personality': 770,\n",
       "         'sports personality': 657,\n",
       "         'radio station': 22,\n",
       "         'product': 1129,\n",
       "         'videogame hardware': 470,\n",
       "         'stocks': 327,\n",
       "         'political race': 75,\n",
       "         'coach': 234,\n",
       "         'sports series': 143,\n",
       "         'cricket match': 196,\n",
       "         'videogame personality ': 123,\n",
       "         'fields of study': 421,\n",
       "         'book genre': 254,\n",
       "         'videogame publisher': 204,\n",
       "         'travel': 59,\n",
       "         'tv genres': 285,\n",
       "         'esports team': 61,\n",
       "         'tv channels': 103,\n",
       "         'award show': 832,\n",
       "         'fictional character': 30,\n",
       "         'unified twitter taxonomy': 7,\n",
       "         'weather': 2,\n",
       "         'place': 45,\n",
       "         'points of interest': 26,\n",
       "         'colleges & universities': 206,\n",
       "         'baseball game': 67,\n",
       "         'concert': 41,\n",
       "         'soccer match': 3,\n",
       "         'animals': 33,\n",
       "         'product version': 35,\n",
       "         'viral accounts': 24,\n",
       "         'esports league': 33,\n",
       "         'esports player': 44,\n",
       "         'song': 7,\n",
       "         'podcast': 21,\n",
       "         'videogame conference': 5,\n",
       "         'american football game': 7,\n",
       "         'nfl football game': 7,\n",
       "         'emergency events': 3,\n",
       "         'book': 2})"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annot_frequency = Counter(np.concatenate(random_tweets['annotations']))\n",
    "annot_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_least_frequenty_annotation(x):\n",
    "    if (len(x)==0):\n",
    "        return 'Unkown'\n",
    "    least_freq = x[0]\n",
    "    for name in x[1:]:\n",
    "        if (annot_frequency[name] < annot_frequency[least_freq]):\n",
    "            least_freq = name\n",
    "    return least_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tweets['annotations'] = random_tweets['annotations'].apply(get_least_frequenty_annotation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>annotations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1537860083668832256</td>\n",
       "      <td>Jeongin now joining the crew and his weapon is...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1537843356767621122</td>\n",
       "      <td>Choeaedol giveaway ! follow  like and rt  drop...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1537853213411627009</td>\n",
       "      <td>Jeon jungkook was embarrassed to do the ending...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1537842564048494593</td>\n",
       "      <td>Roses noodles and doughnuts ed frost and daugh...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>1537859576145772544</td>\n",
       "      <td>Presence on the global stage means that the wo...</td>\n",
       "      <td>music</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id                                               text  \\\n",
       "1   1537860083668832256  Jeongin now joining the crew and his weapon is...   \n",
       "13  1537843356767621122  Choeaedol giveaway ! follow  like and rt  drop...   \n",
       "38  1537853213411627009  Jeon jungkook was embarrassed to do the ending...   \n",
       "41  1537842564048494593  Roses noodles and doughnuts ed frost and daugh...   \n",
       "42  1537859576145772544  Presence on the global stage means that the wo...   \n",
       "\n",
       "   annotations  \n",
       "1        music  \n",
       "13       music  \n",
       "38       music  \n",
       "41       music  \n",
       "42       music  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_test = random_tweets[random_tweets['annotations'].isin(targets)]\n",
    "base_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'music': 3972, 'city': 1037, 'videogame': 1265, 'sport': 278})"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(base_test['annotations'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ea365085f3807110e1cdcb04122fb278047fe100a09bc2730588139759355b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
